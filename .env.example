# =============================================================================
# BrinChat Environment Configuration Example
# =============================================================================
# Copy this file to .env and fill in your values

# =============================================================================
# OpenClaw API (Claude via OpenAI-compatible endpoint)
# =============================================================================
OPENCLAW_API_URL=http://127.0.0.1:18789/v1
OPENCLAW_API_KEY=your-openclaw-api-key
CLAUDE_MODEL=openclaw:main

# =============================================================================
# Session Routing
# =============================================================================
# Primary user shares the main OpenClaw session for unified context
# Other users get isolated sessions + automatic task extraction
OPENCLAW_PRIMARY_USER_ID=0                    # User ID to share main session (0 = disabled)
OPENCLAW_PRIMARY_USERNAME=                     # Username to share main session (case-insensitive)
OPENCLAW_MAIN_SESSION_KEY=agent:main:main

# =============================================================================
# Nextcloud Deck Integration (Task Extraction)
# =============================================================================
# Tasks from non-primary users are extracted to Deck cards
NEXTCLOUD_URL=http://localhost:8080
NEXTCLOUD_USER=admin
NEXTCLOUD_PASS=your-password
DECK_BOARD_ID=2
DECK_BACKLOG_STACK_ID=5

# =============================================================================
# Ollama (Embeddings)
# =============================================================================
OLLAMA_BASE_URL=http://localhost:11434

# =============================================================================
# Uncensored Mode Models
# =============================================================================
# Generic naming - swap models easily as hardware improves
# Old LEXI_*/OMEGA_* env vars still work as fallbacks for backwards compatibility

# Chat model - main conversational AI for uncensored mode
UNCENSORED_CHAT_MODEL=taozhiyuai/llama-3-8b-lexi-uncensored:v1_q8_0

# Tool model - decides which tool to use (fast, small, doesn't need uncensored)
UNCENSORED_TOOL_MODEL=ministral-3:latest

# Vision model - describes images (must have vision capability)
UNCENSORED_VISION_MODEL=huihui_ai/qwen3-vl-abliterated:latest

# Shared settings for uncensored mode
UNCENSORED_BASE_URL=http://localhost:11434
UNCENSORED_TIMEOUT=60
UNCENSORED_TOOL_TIMEOUT=30
UNCENSORED_VISION_TIMEOUT=30

# =============================================================================
# Image/Video Generation (fal.ai)
# =============================================================================
# Get your API key at: https://fal.ai/dashboard/keys
FAL_KEY=

# =============================================================================
# Brave Search API
# =============================================================================
BRAVE_SEARCH_API_KEY=

# =============================================================================
# Authentication
# =============================================================================
JWT_SECRET=change-this-to-a-long-random-string
COOKIE_SECURE=false                            # Set to true for HTTPS
ADULT_PASSCODE=                                # Passcode for uncensored mode access

# =============================================================================
# Voice Configuration
# =============================================================================
VOICE_ENABLED=false

# TTS Backend Options:
#   - edge: Microsoft Edge TTS (good quality, ~0.5s latency, online)
#   - openai: OpenAI-compatible endpoint (e.g., local Qwen3-TTS)
TTS_BACKEND=edge
TTS_MODEL=default

# STT Backend Options:
#   - openai: OpenAI-compatible Whisper endpoint
#   - faster_whisper: Local faster-whisper
STT_BACKEND=openai
STT_MODEL=http://localhost:5001

# =============================================================================
# Server Configuration
# =============================================================================
APP_HOST=0.0.0.0
APP_PORT=8081
LOG_LEVEL=INFO

# =============================================================================
# CORS Configuration
# =============================================================================
CORS_ORIGINS=http://localhost:8081,http://127.0.0.1:8081

# Trusted proxies for correct client IP detection (comma-separated)
TRUSTED_PROXIES=

# =============================================================================
# Database
# =============================================================================
DATABASE_PATH=peanutchat.db

# =============================================================================
# Knowledge Base
# =============================================================================
KB_EMBEDDING_MODEL=nomic-embed-text
KB_CHUNK_SIZE=512
KB_CHUNK_OVERLAP=50

# =============================================================================
# Streaming Limits
# =============================================================================
# Soft limits (log warning but continue)
THINKING_TOKEN_LIMIT_INITIAL=3000
THINKING_TOKEN_LIMIT_FOLLOWUP=2000
# Hard limits (break stream)
THINKING_HARD_LIMIT_INITIAL=30000
THINKING_HARD_LIMIT_FOLLOWUP=20000
CHAT_REQUEST_TIMEOUT=300

# =============================================================================
# Background Processing
# =============================================================================
EXTRACTION_MODEL=qwen2.5-coder:3b              # Small model for memory extraction
